# Implementation Plan: Deepfake Detection AI Competition Platform

**Branch**: `001-deepfake-detection-competition` | **Date**: 2025-11-17 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/001-deepfake-detection-competition/spec.md`

**Note**: This plan was generated by the `/speckit.plan` command based on competition requirements and state-of-the-art research.

## Summary

Develop a competitive deepfake detection model for the National Forensic Service AI Competition that classifies face-based images and videos as Real (0) or Fake (1) with high Macro F1-score. The implementation uses a dual-branch hybrid architecture combining spatial features (EfficientNet-B4 + Vision Transformer) with frequency domain analysis (FFT/DCT) to maximize generalization across diverse deepfake generation methods. The model will be trained on multiple public datasets (FaceForensics++, DFDC, Celeb-DF) with strong data augmentation and optimized for Macro F1-score through combined loss functions. The system must complete inference within 3 hours on private test data while adhering to competition rules (single model, no ensembles, reproducible results).

## Technical Context

**Language/Version**: Python 3.9 (CUDA 11.8 environment - competition requirement)
**Primary Dependencies**: PyTorch 1.13.1, timm (EfficientNet/ViT), opencv-python-headless, albumentations, facenet-pytorch/retinaface-pytorch (face detection), pandas, scikit-learn, numpy, scipy
**Storage**: Local file system for training datasets (FaceForensics++, DFDC, Celeb-DF), model checkpoints stored as .pth files, submission.csv output for competition
**Testing**: pytest for unit/integration tests, manual validation on competition sample data, cross-dataset validation for generalization testing
**Target Platform**: Linux cloud inference environment (8-core CPU, 48GB RAM, L4/T4 GPU with CUDA 11.8), local development on GPU workstation
**Project Type**: Single machine learning project (deep learning model with training, inference, and submission components)
**Performance Goals**:
- Training: Achieve Macro F1-score >82% on cross-dataset validation
- Inference: Process ~10,000 mixed image/video test samples within 3 hours (<2 hours target for safety margin)
- Model accuracy: Macro F1 >80% on unseen competition test data
- Throughput: ~20-30ms per image, ~0.5-1s per video (16 frames)

**Constraints**:
- Single model architecture only (no ensemble voting - competition rule)
- No test-time training or pseudo-labeling (competition rule)
- 3-hour maximum inference time (hard deadline)
- Network access disabled during inference phase
- Must use publicly available training data with proper licensing
- Reproducible results required for verification period
- Korean citizenship requirement for participants (administrative constraint)

**Scale/Scope**:
- Training data: ~130,000+ videos and images from 3 major datasets
- Model size: ~50-100M parameters (EfficientNet-B4 based)
- Inference workload: ~10,000 test samples (estimated)
- Development timeline: 6 weeks from research to submission
- Code base: ~2,000-3,000 lines of Python (models, data processing, training, inference)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

**Status**: N/A - Constitution file is empty template, no specific principles defined yet.

**Notes**:
- This is a competition submission project with external rules and constraints
- Following general software engineering best practices: modularity, testability, documentation
- Adhering to competition-specific requirements: single model, reproducibility, no ensembles
- Code quality standards: type hints, docstrings, error handling, logging

## Project Structure

### Documentation (this feature)

```text
specs/001-deepfake-detection-competition/
├── spec.md                           # Feature specification (competition requirements)
├── plan.md                           # This file - implementation plan
├── research.md                       # State-of-the-art techniques research (2023-2024)
├── data-model.md                     # Architecture, data schemas, model design
├── quickstart.md                     # Getting started guide for implementation
├── contracts/
│   └── model-interface.md            # Programmatic interfaces and API contracts
├── checklists/
│   └── requirements.md               # Specification quality validation
└── tasks.md                          # Implementation tasks (to be generated by /speckit.tasks)
```

### Source Code (repository root)

```text
deepfake-detection/
├── src/                              # Main source code
│   ├── models/                       # Model architectures
│   │   ├── __init__.py
│   │   ├── deepfake_detector.py      # Main dual-branch model
│   │   ├── spatial_branch.py         # EfficientNet + Transformer
│   │   ├── frequency_branch.py       # FFT/DCT feature extraction
│   │   └── fusion_layer.py           # Attention-based fusion
│   ├── data/                         # Data processing
│   │   ├── __init__.py
│   │   ├── dataset.py                # PyTorch Dataset classes
│   │   ├── face_detector.py          # Face detection (RetinaFace/MTCNN)
│   │   ├── video_processor.py        # Video frame extraction
│   │   └── transforms.py             # Data augmentation pipeline
│   ├── training/                     # Training components
│   │   ├── __init__.py
│   │   ├── trainer.py                # Training loop orchestration
│   │   ├── losses.py                 # Loss functions (CE, Focal, F1)
│   │   └── metrics.py                # Evaluation metrics (Macro F1)
│   ├── inference/                    # Inference pipeline
│   │   ├── __init__.py
│   │   ├── inference_engine.py       # Main inference orchestration
│   │   └── model_loader.py           # Checkpoint loading
│   └── utils/                        # Utilities
│       ├── __init__.py
│       ├── config.py                 # Configuration management
│       └── logger.py                 # Logging setup
├── configs/                          # Configuration files
│   ├── model_config.yaml             # Model architecture settings
│   ├── training_config.yaml          # Training hyperparameters
│   └── inference_config.yaml         # Inference settings
├── scripts/                          # Executable scripts
│   ├── train.py                      # Main training script
│   ├── evaluate.py                   # Model evaluation
│   ├── inference.py                  # Standalone inference
│   ├── preprocess_data.py            # Dataset preprocessing
│   └── test_submission.py            # Validate submission format
├── notebooks/                        # Jupyter notebooks
│   ├── eda.ipynb                     # Exploratory data analysis
│   ├── experiments.ipynb             # Model experiments
│   └── task.ipynb                    # Competition submission notebook
├── tests/                            # Test suite
│   ├── unit/                         # Unit tests
│   │   ├── test_models.py            # Model architecture tests
│   │   ├── test_data.py              # Data processing tests
│   │   └── test_metrics.py           # Metrics computation tests
│   ├── integration/                  # Integration tests
│   │   ├── test_training.py          # End-to-end training test
│   │   └── test_inference.py         # End-to-end inference test
│   └── contract/                     # Contract tests
│       └── test_interfaces.py        # Verify interface compliance
├── data/                             # Training and test data
│   ├── faceforensics/                # FF++ dataset
│   ├── dfdc/                         # DFDC dataset
│   ├── celebdf/                      # Celeb-DF dataset
│   └── sample/                       # Competition sample data
├── checkpoints/                      # Trained model weights
│   └── .gitkeep                      # Track directory in git
├── logs/                             # Training logs
│   └── .gitkeep
├── requirements.txt                  # Python dependencies
├── setup.py                          # Package installation
├── README.md                         # Project documentation
└── .gitignore                        # Git ignore rules
```

**Structure Decision**:

This is a **single project structure** optimized for deep learning model development and competition submission. The organization follows standard PyTorch project conventions:

- **src/**: Modular source code organized by function (models, data, training, inference)
- **configs/**: YAML configuration files for reproducibility and easy experimentation
- **scripts/**: Command-line entry points for training, evaluation, and inference
- **notebooks/**: Interactive development and the critical task.ipynb submission file
- **tests/**: Comprehensive test coverage (unit, integration, contract)
- **data/**: Dataset storage (excluded from git via .gitignore)
- **checkpoints/**: Model weights (excluded from git, included in submission)

This structure supports:
1. **Development**: Clear separation of concerns, easy to navigate
2. **Testing**: Isolated components for unit testing, full pipeline for integration testing
3. **Competition Submission**: task.ipynb can import from src/ modules
4. **Reproducibility**: Configurations separate from code, checkpoint management
5. **Collaboration**: Standard structure familiar to ML practitioners

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

**Status**: No violations. Project follows competition requirements and standard ML engineering practices.

## Implementation Phases

This implementation follows a structured 6-week development timeline divided into 4 phases:

### Phase 0: Research (Completed)
**Duration**: Preliminary
**Deliverable**: research.md

- ✓ Surveyed state-of-the-art deepfake detection techniques (2023-2024)
- ✓ Identified top architectures: EfficientNet, Vision Transformers, Frequency domain analysis
- ✓ Analyzed competition metrics (Macro F1-score optimization strategies)
- ✓ Reviewed best practices for generalization and cross-dataset robustness
- ✓ Selected dual-branch hybrid architecture as recommended approach

**Key Findings**: Frequency domain features + spatial features with multi-dataset training achieves best generalization. EfficientNet-B4 provides optimal speed/accuracy tradeoff.

### Phase 1: Design & Contracts (Completed)
**Duration**: Preliminary
**Deliverables**: data-model.md, contracts/model-interface.md, quickstart.md, plan.md (this file)

- ✓ Designed dual-branch model architecture (spatial + frequency)
- ✓ Defined data schemas for training and inference
- ✓ Specified programmatic interfaces for all components
- ✓ Created quickstart guide for implementation
- ✓ Documented project structure and technical context

**Key Outputs**: Complete technical specification ready for implementation.

### Phase 2: Baseline Implementation (Weeks 1-2)
**Goal**: Working pipeline with basic EfficientNet model achieving >85% accuracy on FaceForensics++

**Tasks**:
1. Environment setup and dependency installation (Day 1)
2. **Data Preparation** (Days 1-7, parallel execution):
   - Task 2a: Download FaceForensics++ (~500GB, 3-5 days depending on network)
   - Task 2b: Download DFDC (~470GB, 4-7 days depending on network)
   - Task 2c: Download Celeb-DF (~tens of GB, 1-2 days)
   - Task 2d: Implement face detection module (RetinaFace/MTCNN) while downloads proceed
   - Task 2e: Preprocess FF++ (face detection, normalization, 1-3 days after download)
   - Task 2f: Preprocess DFDC (parallel processing, 1-3 days after download)
   - Task 2g: Preprocess Celeb-DF (parallel processing, 1-2 days after download)
3. Create dataset classes with data augmentation (Day 8)
4. Build baseline EfficientNet-B4 model (Day 9)
5. Implement training loop with Cross-Entropy loss (Day 10)
6. Train baseline model on FaceForensics++ (Days 11-13)
7. Validate performance metrics (accuracy, Macro F1) (Day 14)

**Data Preparation Schedule**:
- **Week 1**: All dataset downloads initiated in parallel on Day 1; face detection module development (Days 2-4); begin preprocessing as datasets complete download
- **Week 2**: Complete preprocessing for all datasets; integrate into training pipeline

**Success Criteria**:
- All datasets downloaded and preprocessed by end of Week 2
- Face detection works on sample images/videos
- Data pipeline loads and augments correctly
- Baseline model trains without errors
- Validation accuracy >85% on FF++ test set
- Macro F1-score tracked and reported

### Phase 3: Hybrid Model Development (Weeks 3-4)
**Goal**: Dual-branch architecture with multi-dataset training achieving >80% cross-dataset F1

**Tasks**:
1. Implement Frequency Branch (FFT/DCT analysis)
2. Implement Vision Transformer encoder for spatial branch
3. Build attention-based fusion layer
4. Integrate spatial and frequency branches into unified model
5. Implement combined loss function (CE + Focal + F1)
6. Setup multi-dataset training (FF++ + DFDC + Celeb-DF)
7. Implement cross-dataset validation
8. Train hybrid model with balanced sampling
9. Optimize for Macro F1-score
10. Analyze per-class performance and adjust as needed

**Success Criteria**:
- Dual-branch model forward pass works correctly
- Combined loss converges during training
- Cross-dataset validation F1 >80%
- Balanced precision/recall for Real and Fake classes
- Model generalizes across different datasets

### Phase 4: Optimization & Submission (Weeks 5-6)
**Goal**: Optimize inference speed, finalize submission notebook, submit before deadline

**Tasks**:
1. Implement video frame sampling and aggregation
2. Optimize inference pipeline (batch processing, FP16)
3. Benchmark inference time on test-sized data
4. Create task.ipynb submission notebook
5. Package model checkpoints and dependencies
6. Test submission locally (format, reproducibility)
7. Validate on competition sample data
8. Document all preprocessing steps for verification
9. Retrieve competition key for CUDA 11.8
10. Submit to competition platform
11. Monitor leaderboard results
12. Prepare for verification period (Nov 21-26)

**Success Criteria**:
- Inference completes in <2 hours on ~10K samples
- submission.csv format validated
- task.ipynb runs end-to-end without errors
- Results reproducible across multiple runs
- Successful submission to competition platform
- Leaderboard Macro F1 >80% (target: 82%+)

## Risk Mitigation Strategies

### Risk 1: Generalization Failure
**Probability**: Medium
**Impact**: High (poor competition performance)

**Mitigation**:
- Train on multiple diverse datasets (FF++, DFDC, Celeb-DF)
- Use strong data augmentation (compression, noise, color jitter)
- Implement frequency domain analysis for robust features
- Validate on held-out cross-dataset splits
- Monitor cross-dataset metrics during training

**Fallback**: If generalization poor, increase augmentation strength, add more training data, or simplify model to reduce overfitting.

### Risk 2: Inference Time Exceeds Limit
**Probability**: Low
**Impact**: Critical (disqualification)

**Mitigation**:
- Use EfficientNet-B4 (not B7) for speed
- Limit video frame sampling to 16 frames
- Implement batch processing and FP16
- Benchmark early and often
- Build in 1-hour safety margin (target <2 hours)

**Fallback**: Reduce model size to EfficientNet-B3, decrease video frames to 8, lower input resolution to 224×224.

### Risk 3: Verification Failure
**Probability**: Low
**Impact**: High (score invalidated)

**Mitigation**:
- Fix all random seeds (numpy, torch, python)
- Document preprocessing steps thoroughly
- Test reproducibility locally 3+ times
- Version control all code and configs
- Save exact dependency versions

**Fallback**: If initial verification fails, debug discrepancies and resubmit if allowed.

### Risk 4: Class Imbalance in Test Data
**Probability**: Medium
**Impact**: Medium (suboptimal Macro F1)

**Mitigation**:
- Optimize for Macro F1 (not accuracy)
- Use balanced sampling during training
- Monitor per-class metrics (precision/recall for both Real and Fake)
- Use combined loss function targeting F1

**Fallback**: Adjust decision threshold post-hoc if validation reveals bias.

### Risk 5: Out of Memory (OOM) Errors
**Probability**: Medium
**Impact**: Medium (inference failure)

**Root Cause Analysis**:
- L4 GPU: 24GB VRAM (typical allocation)
- T4 GPU: 16GB VRAM (fallback if L4 queue is long)
- EfficientNet-B4: ~50-100M parameters (~200-400MB model weights in FP32)
- Batch size 32 with 224×224 RGB images: ~32 × 3 × 224 × 224 × 4 bytes ≈ 19MB input batch
- Intermediate activations: ~2-4GB (depends on architecture depth)
- **Critical Constraint**: With dual-branch architecture (spatial + frequency), memory usage can exceed 8-10GB

**Mitigation Strategy (Tiered Approach)**:

**Phase 2 (Baseline) - Early Detection**:
1. **Memory Profiling Benchmark** (Day 2-3):
   - Measure baseline EfficientNet-B4 memory usage on L4/T4
   - Test batch sizes: 16, 32, 64 with 224×224 input
   - Document peak memory usage and safe operating limits
   - **Success Criteria**: Identify maximum safe batch size before proceeding

2. **Monitoring During Development**:
   - Use `torch.cuda.max_memory_allocated()` to track peak usage
   - Log memory usage after each training epoch
   - Set memory alerts at 80% utilization threshold

**Phase 3 (Hybrid Model) - Proactive Optimization**:
3. **Architecture-Specific Strategies**:
   - **Gradient Checkpointing**: Trade compute for memory (reduces activation memory by 30-50%)
   - **Mixed Precision (FP16)**: Halves memory usage for activations and weights (~2x speedup)
   - **Batch Size Adjustment**: Start with batch size 32; if OOM occurs:
     - Step 1: Reduce to 16
     - Step 2: Use gradient accumulation (accumulate over 2 steps to simulate batch 32)
   - **Input Resolution Fallback**: If still OOM at batch 16, reduce from 224×224 to 192×192

4. **Video Processing Optimization**:
   - Default: 16 frames per video
   - If OOM: Reduce to 8 frames
   - Ensure frame batch processing doesn't exceed memory limits

**Phase 4 (Inference) - Runtime Safety**:
5. **Inference-Time Safeguards**:
   - Pre-allocate tensors to avoid fragmentation
   - Clear GPU cache between batches: `torch.cuda.empty_cache()`
   - Implement fallback pipeline:
     - Primary: Batch size 64 (fast path)
     - Fallback 1: Batch size 32 (if OOM detected)
     - Fallback 2: Batch size 16 (if still OOM)
     - Fallback 3: Batch size 1 + CPU offload (last resort)

**Expected Memory Budget**:
| Component | Memory Usage (FP32) | Memory Usage (FP16) |
|-----------|--------------------:|--------------------:|
| Model Weights (EfficientNet-B4 dual-branch) | ~600MB | ~300MB |
| Input Batch (32 × 224×224×3) | ~19MB | ~10MB |
| Intermediate Activations (batch 32) | ~3-4GB | ~1.5-2GB |
| Frequency Branch Processing | ~1-2GB | ~0.5-1GB |
| **Total Estimated** | **~5-7GB** | **~2.5-3.5GB** |

**Decision Points**:
- **If using L4 (24GB)**: Safe to use batch size 64 with FP16, or batch size 32 with FP32
- **If using T4 (16GB)**: MUST use FP16 + batch size 32 maximum, or batch size 16 with FP32
- **If OOM persists**: Reduce model to EfficientNet-B3 (smaller backbone, -30% memory)

**Fallback Sequence** (if OOM occurs during submission inference):
1. Enable mixed precision (FP16) → Expected 50% memory reduction
2. Reduce batch size to 16 → Expected 50% memory reduction
3. Reduce video frames from 16 to 8 → Expected 50% video memory reduction
4. Reduce input resolution from 224×224 to 192×192 → Expected 30% reduction
5. Downgrade to EfficientNet-B3 backbone → Expected 30-40% reduction
6. CPU fallback for problematic samples (last resort, slow but functional)

**Early Warning System**:
- Implement try-except blocks around batch processing
- Log OOM errors with batch size and input dimensions
- Automatically retry with reduced batch size on OOM
- Track retry statistics to identify problematic samples

## Key Technical Decisions

### Decision 1: Dual-Branch Architecture
**Rationale**: 2024 research shows frequency domain features significantly improve generalization (+9.8% in FreqNet paper). Combining spatial and frequency analysis leverages complementary information.

**Alternatives Considered**:
- Pure CNN (EfficientNet only): Simpler but worse generalization
- Pure Transformer: Slower inference, requires more data
- Ensemble of models: Violates competition rules

**Trade-offs**: Additional complexity and compute cost, but superior generalization justifies it.

### Decision 2: Multi-Dataset Training
**Rationale**: Cross-dataset performance drops by 45-50% in 2024 benchmarks. Training on diverse data is critical for real-world generalization.

**Alternatives Considered**:
- Single dataset (FF++ only): Faster to implement but poor generalization
- Domain adaptation: More complex, uncertain benefit

**Trade-offs**: Longer training time, more data management, but essential for competition success.

### Decision 3: EfficientNet-B4 Backbone
**Rationale**: All DFDC winners used EfficientNet. B4 provides best speed/accuracy balance for 3-hour constraint.

**Alternatives Considered**:
- EfficientNet-B7: Higher accuracy but 2x slower
- ResNet/Xception: Good performance but EfficientNet proven in competitions
- ViT from scratch: Requires massive data, slower

**Trade-offs**: B4 is slightly less accurate than B7 but fast enough to meet time constraints.

### Decision 4: Combined Loss Function
**Rationale**: Direct optimization of Macro F1-score through differentiable F1 loss, augmented with CE and Focal for stable training.

**Alternatives Considered**:
- Cross-Entropy only: Doesn't directly optimize F1
- Focal loss only: Helps with hard examples but not F1-specific
- Threshold tuning: Post-hoc optimization, less principled

**Trade-offs**: More complex loss implementation but directly targets competition metric.

## Dependencies & External Resources

### Required Datasets (Public, Licensed for Competition Use)
1. **FaceForensics++**: https://github.com/ondyari/FaceForensics (free for research)
2. **DFDC**: https://ai.facebook.com/datasets/dfdc/ (free for research)
3. **Celeb-DF**: https://github.com/yuezunli/celeb-deepfakeforensics (free for research)

**Storage Requirements**: ~500GB total (DFDC is largest at ~470GB)

### Key Python Libraries
- PyTorch 1.13.1 (deep learning framework)
- timm 0.9.12 (pretrained models)
- albumentations 1.3.1 (data augmentation)
- opencv-python-headless (video processing)
- facenet-pytorch or retinaface-pytorch (face detection)

### Competition-Specific
- aifactory library (submission API)
- Competition key for CUDA 11.8 environment

### Development Tools
- Jupyter Notebook (for task.ipynb)
- pytest (testing)
- YAML (configuration)
- Git (version control)

## Success Metrics

### Development Metrics
- **Baseline Model**: Accuracy >85% on FF++ test set
- **Hybrid Model**: Cross-dataset Macro F1 >80%
- **Inference Speed**: <2 hours for 10K samples
- **Reproducibility**: Identical results across 3+ runs

### Competition Metrics
- **Primary**: Macro F1-score >80% (minimum viable)
- **Target**: Macro F1-score >82% (competitive)
- **Stretch Goal**: Macro F1-score >88% (award-winning)

### Process Metrics
- All unit tests passing
- Integration tests covering full pipeline
- Code coverage >80% for critical modules
- Documentation complete for all public interfaces

## Timeline Summary

| Week | Phase | Milestone |
|------|-------|-----------|
| Pre | Phase 0-1 | Research & Design Complete |
| 1-2 | Phase 2 | Baseline model trained, >85% FF++ accuracy |
| 3-4 | Phase 3 | Hybrid model trained, >80% cross-dataset F1 |
| 5 | Phase 4a | Inference optimized, <2 hour runtime |
| 6 | Phase 4b | Submission complete, results on leaderboard |
| Nov 21-26 | Verification | Score reproducibility confirmed |
| Nov 27 | Award Announcement | Final results |

## Next Steps

1. **Generate Implementation Tasks**: Run `/speckit.tasks` to create detailed task breakdown
2. **Setup Development Environment**: Install dependencies, configure GPU environment
3. **Begin Phase 2**: Implement baseline model and data pipeline
4. **Iterative Development**: Follow phase timeline, monitor metrics, adjust as needed
5. **Submit by Deadline**: November 20, 2025, 5 PM (competition deadline)

This plan provides a comprehensive roadmap from research to submission, balancing technical rigor with practical competition constraints.
