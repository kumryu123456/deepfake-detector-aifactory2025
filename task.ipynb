{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Detection Competition - Submission Notebook\n",
    "\n",
    "This notebook implements the complete inference pipeline for the **딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회**.\n",
    "\n",
    "## Competition Details\n",
    "- **Platform**: AI Factory\n",
    "- **Metric**: Macro F1-score\n",
    "- **Input**: Mixed image/video files in `./data/`\n",
    "- **Output**: `submission.csv` with columns [filename, label]\n",
    "- **Labels**: 0 = Real, 1 = Fake\n",
    "\n",
    "## Pipeline Overview\n",
    "1. Install dependencies\n",
    "2. Load trained model checkpoint\n",
    "3. Initialize inference engine\n",
    "4. Process test data\n",
    "5. Generate submission.csv\n",
    "6. Validate format\n",
    "7. Submit to AI Factory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install PyTorch 1.13.1+cu118 and required packages for CUDA 11.8 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install PyTorch with CUDA 11.8 support\n",
    "pip install -q torch==1.13.1+cu118 torchvision==0.14.1+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install core dependencies\n",
    "pip install -q timm==0.9.2 opencv-python-headless==4.8.1.78 albumentations==1.3.1\n",
    "pip install -q pandas==2.0.3 scikit-learn==1.3.0 pyyaml==6.0.1 tqdm==4.66.1\n",
    "\n",
    "# Install face detection libraries\n",
    "pip install -q facenet-pytorch==2.5.3 mediapipe==0.10.3\n",
    "\n",
    "echo \"Dependencies installed successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Modules\n",
    "\n",
    "Import all required modules and add src to Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "src_path = Path(\"./src\").resolve()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Standard library imports\n",
    "import time\n",
    "import warnings\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Project imports\n",
    "from inference import create_inference_engine\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Set up inference configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference configuration\n",
    "CONFIG = {\n",
    "    # Model checkpoint\n",
    "    \"checkpoint_path\": \"checkpoints/best.pth\",\n",
    "    \n",
    "    # Data paths\n",
    "    \"data_dir\": \"./data\",\n",
    "    \"output_path\": \"submission.csv\",\n",
    "    \n",
    "    # Inference settings\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"use_fp16\": True,  # Use mixed precision for faster inference\n",
    "    \"batch_size\": 64,  # Batch size for image processing\n",
    "    \"video_frames\": 16,  # Number of frames to extract per video\n",
    "    \n",
    "    # Face detection\n",
    "    \"face_detector\": \"mtcnn\",  # Options: mtcnn, retinaface, mediapipe\n",
    "    \n",
    "    # Verbose output\n",
    "    \"verbose\": True,\n",
    "}\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 80)\n",
    "print(\"INFERENCE CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validate Paths\n",
    "\n",
    "Check that required files and directories exist before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate checkpoint exists\n",
    "checkpoint_path = Path(CONFIG[\"checkpoint_path\"])\n",
    "if not checkpoint_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Model checkpoint not found: {checkpoint_path}\\n\"\n",
    "        f\"Please ensure the checkpoint file exists before running inference.\"\n",
    "    )\n",
    "print(f\"✅ Checkpoint found: {checkpoint_path}\")\n",
    "print(f\"   Size: {checkpoint_path.stat().st_size / 1024**2:.1f} MB\")\n",
    "\n",
    "# Validate data directory exists\n",
    "data_dir = Path(CONFIG[\"data_dir\"])\n",
    "if not data_dir.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Data directory not found: {data_dir}\\n\"\n",
    "        f\"Please ensure the test data is available in ./data/\"\n",
    "    )\n",
    "print(f\"✅ Data directory found: {data_dir}\")\n",
    "\n",
    "# Count files in data directory\n",
    "image_extensions = {\".jpg\", \".jpeg\", \".png\"}\n",
    "video_extensions = {\".mp4\", \".avi\", \".mov\"}\n",
    "\n",
    "all_files = list(data_dir.glob(\"*\"))\n",
    "num_images = sum(1 for f in all_files if f.suffix.lower() in image_extensions)\n",
    "num_videos = sum(1 for f in all_files if f.suffix.lower() in video_extensions)\n",
    "\n",
    "print(f\"\\nTest data statistics:\")\n",
    "print(f\"  Total files: {len(all_files)}\")\n",
    "print(f\"  Images: {num_images}\")\n",
    "print(f\"  Videos: {num_videos}\")\n",
    "\n",
    "if len(all_files) == 0:\n",
    "    raise ValueError(\"No test files found in data directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Inference Engine\n",
    "\n",
    "Create the inference engine with the trained model and preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInitializing inference engine...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # Create inference engine\n",
    "    engine = create_inference_engine(\n",
    "        checkpoint_path=CONFIG[\"checkpoint_path\"],\n",
    "        device=CONFIG[\"device\"],\n",
    "        use_fp16=CONFIG[\"use_fp16\"],\n",
    "        batch_size=CONFIG[\"batch_size\"],\n",
    "        video_frames=CONFIG[\"video_frames\"],\n",
    "        face_detector_name=CONFIG[\"face_detector\"],\n",
    "        verbose=CONFIG[\"verbose\"],\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Inference engine initialized successfully!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Failed to initialize inference engine: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Inference\n",
    "\n",
    "Process all test files and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRunning inference on test data...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Run inference\n",
    "    results_df = engine.run_inference(\n",
    "        data_dir=CONFIG[\"data_dir\"],\n",
    "        output_path=CONFIG[\"output_path\"],\n",
    "    )\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"INFERENCE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "    print(f\"Average time per file: {elapsed_time / len(results_df):.3f} seconds\")\n",
    "    print(f\"\\nPrediction statistics:\")\n",
    "    print(f\"  Total predictions: {len(results_df)}\")\n",
    "    print(f\"  Real (0): {sum(results_df['label'] == 0)} ({sum(results_df['label'] == 0) / len(results_df) * 100:.1f}%)\")\n",
    "    print(f\"  Fake (1): {sum(results_df['label'] == 1)} ({sum(results_df['label'] == 1) / len(results_df) * 100:.1f}%)\")\n",
    "    print(f\"\\nOutput saved to: {CONFIG['output_path']}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display sample predictions\n",
    "    print(\"\\nSample predictions (first 10 rows):\")\n",
    "    print(results_df.head(10).to_string(index=False))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Inference failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validate Submission Format\n",
    "\n",
    "Verify that submission.csv meets competition requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_submission(csv_path: str) -> bool:\n",
    "    \"\"\"Validate submission.csv format.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to submission.csv\n",
    "        \n",
    "    Returns:\n",
    "        True if valid, False otherwise\n",
    "    \"\"\"\n",
    "    print(\"\\nValidating submission format...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    errors = []\n",
    "    warnings = []\n",
    "    \n",
    "    try:\n",
    "        # Load submission\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Check columns\n",
    "        expected_columns = [\"filename\", \"label\"]\n",
    "        if list(df.columns) != expected_columns:\n",
    "            errors.append(\n",
    "                f\"Invalid columns: {df.columns.tolist()}. \"\n",
    "                f\"Expected: {expected_columns}\"\n",
    "            )\n",
    "        \n",
    "        # Check for null values\n",
    "        null_counts = df.isnull().sum()\n",
    "        if null_counts.any():\n",
    "            for col in null_counts[null_counts > 0].index:\n",
    "                errors.append(f\"Column '{col}' has {null_counts[col]} null values\")\n",
    "        \n",
    "        # Check label values\n",
    "        if \"label\" in df.columns:\n",
    "            unique_labels = df[\"label\"].unique()\n",
    "            invalid_labels = [l for l in unique_labels if l not in [0, 1]]\n",
    "            \n",
    "            if invalid_labels:\n",
    "                errors.append(\n",
    "                    f\"Invalid label values: {invalid_labels}. \"\n",
    "                    f\"Labels must be 0 (Real) or 1 (Fake)\"\n",
    "                )\n",
    "            \n",
    "            # Check label data type\n",
    "            if not pd.api.types.is_integer_dtype(df[\"label\"]):\n",
    "                warnings.append(\n",
    "                    f\"Label column has non-integer dtype: {df['label'].dtype}\"\n",
    "                )\n",
    "        \n",
    "        # Check filenames\n",
    "        if \"filename\" in df.columns:\n",
    "            # Check for missing extensions\n",
    "            no_extension = df[~df[\"filename\"].str.contains(\".\", regex=False)]\n",
    "            if len(no_extension) > 0:\n",
    "                errors.append(\n",
    "                    f\"{len(no_extension)} filenames missing extensions\"\n",
    "                )\n",
    "            \n",
    "            # Check for duplicates\n",
    "            duplicates = df[df[\"filename\"].duplicated()]\n",
    "            if len(duplicates) > 0:\n",
    "                errors.append(\n",
    "                    f\"{len(duplicates)} duplicate filenames found\"\n",
    "                )\n",
    "        \n",
    "        # Check number of rows\n",
    "        if len(df) == 0:\n",
    "            errors.append(\"Submission is empty (0 rows)\")\n",
    "        \n",
    "        # Print validation results\n",
    "        if errors:\n",
    "            print(\"\\n❌ VALIDATION ERRORS:\")\n",
    "            for i, error in enumerate(errors, 1):\n",
    "                print(f\"  {i}. {error}\")\n",
    "        \n",
    "        if warnings:\n",
    "            print(\"\\n⚠️  WARNINGS:\")\n",
    "            for i, warning in enumerate(warnings, 1):\n",
    "                print(f\"  {i}. {warning}\")\n",
    "        \n",
    "        if not errors and not warnings:\n",
    "            print(\"\\n✅ All validation checks passed!\")\n",
    "        \n",
    "        print(\"\\nSubmission summary:\")\n",
    "        print(f\"  Total rows: {len(df)}\")\n",
    "        if \"label\" in df.columns:\n",
    "            print(f\"  Real (0): {sum(df['label'] == 0)}\")\n",
    "            print(f\"  Fake (1): {sum(df['label'] == 1)}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return len(errors) == 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Validation error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Run validation\n",
    "is_valid = validate_submission(CONFIG[\"output_path\"])\n",
    "\n",
    "if not is_valid:\n",
    "    raise ValueError(\n",
    "        \"Submission validation failed! Please fix the errors before submitting.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Submit to AI Factory\n",
    "\n",
    "Submit the results to the competition platform for automated scoring.\n",
    "\n",
    "**Note**: This cell assumes the `aifactory.score.submit()` function is available in the AI Factory environment. If running locally, this cell will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Submit to AI Factory platform\ntry:\n    import aifactory.score as aif\n\n    print(\"\\nSubmitting to AI Factory...\")\n    print(\"=\" * 80)\n\n    # Submit using Competition Key for CUDA 11.8\n    result = aif.submit(\n        model_name=\"deepfake_detector_efficientnet_b4\",\n        key=\"560ffaf9-b456-444f-b4a5-6cadc116dd5e\"\n    )\n\n    print(\"\\n✅ Submission successful!\")\n    print(f\"Result: {result}\")\n    print(\"=\" * 80)\n\nexcept ImportError:\n    print(\"\\n⚠️  Not running on AI Factory platform\")\n    print(\"   Skipping submission step\")\n    print(\"   To test locally, ensure submission.csv is valid\")\n    print(\"=\" * 80)\nexcept Exception as e:\n    print(f\"\\n❌ Submission failed: {e}\")\n    import traceback\n    traceback.print_exc()\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The inference pipeline has completed successfully:\n",
    "\n",
    "1. ✅ Dependencies installed\n",
    "2. ✅ Model checkpoint loaded\n",
    "3. ✅ Inference engine initialized\n",
    "4. ✅ Test data processed\n",
    "5. ✅ Submission.csv generated\n",
    "6. ✅ Format validated\n",
    "7. ✅ Submitted to AI Factory (if available)\n",
    "\n",
    "The submission.csv file is ready for evaluation!\n",
    "\n",
    "---\n",
    "\n",
    "**딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회**\n",
    "\n",
    "For questions or issues, please contact the competition organizers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}